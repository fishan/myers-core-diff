/**
 * @license
 * Copyright (c) 2025, Internal Implementation
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
const __DEV__ = false;

/**
 * Enumerates the types of operations in a diff result.
 */
export enum DiffOperation {
	/** Represents a part of the sequence that is unchanged. */
	EQUAL,
	/** Represents a part of the sequence that was added. */
	ADD,
	/** Represents a part of the sequence that was removed. */
	REMOVE,
}

/**
 * Represents a single operation in the diff result.
 * It's a tuple where the first element is the operation type
 * and the second is the string content (token).
 */
export type DiffResult = [DiffOperation, string];

// Internal interfaces for the jsdiff-style algorithm implementation.
interface DraftChangeObject {
	op: DiffOperation;
	count: number;
	previousComponent?: DraftChangeObject;
}

interface Path {
	oldPos: number;
	lastComponent?: DraftChangeObject;
}

// Data structure for the result of the middle snake search.
interface MiddleSnake {
	x: number;
	y: number;
	u: number;
	v: number;
}

/**
 * Configuration options for the diff algorithm.
 */
export interface DiffOptions {
	/** [v6.0] The name of the diffing strategy plugin to use. */
	diffStrategyName?: string;
	/** The minimum length of a match to be considered valid. */
	minMatchLength?: number;
	/** The threshold for switching to a faster, less precise diff algorithm for small changes. */
	quickDiffThreshold?: number;
	/** The threshold for using optimizations geared towards very large differences. */
	hugeDiffThreshold?: number;
	/** How far ahead to look for potential matches when guiding the diff algorithm. */
	lookahead?: number;
	/** The width of the "corridor" to search within around the main diagonal. */
	corridorWidth?: number;
	/** If true, skips the initial trimming of common prefixes and suffixes. */
	skipTrimming?: boolean;
	/** */
	jumpStep?: number;
	/** */
	huntChunkSize?: number
	/** */
	minAnchorConfidence?: number;
	/** */
	useAnchors?: boolean;
	/** If true, the diff algorithm will prioritize preserving the positions of equal tokens. (Used by strategies) */
	preservePositions?: boolean;
	/** */
	localgap?: number;
	/** */
	localLookahead?: number;
	/** */
	anchorSearchMode?: 'floating' | 'positional' | 'combo';
	/** */
	positionalAnchorMaxDrift?: number;

}

/**
 * [v6.0] Defines the interface (contract) for a diff strategy plugin.
 * A plugin receives the diff engine instance to access its "Toolbox" of algorithms.
 */
export type DiffStrategyPlugin = (
	engine: MyersCoreDiff, // The engine instance for accessing the Toolbox
	oldTokens: Uint32Array, oldStart: number, oldEnd: number,
	newTokens: Uint32Array, newStart: number, newEnd: number,
	idToString: string[],
	config: Required<DiffOptions>,
	debug: boolean
) => DiffResult[];


/**
 * Represents an anchor, which is a significant, identical block of tokens
 * between the old and new sequences. Anchors guide the diffing process.
 * @internal
 */
export interface Anchor {
	oldPos: number;
	newPos: number;
	length: number;
	driftDistance: number;
	driftRatio: number;
	confidence: number;
}

/**
 * Represents a "gap" between two anchors, which needs to be diffed.
 * @internal
 */
interface GapInfo {
	oldStart: number;
	oldEnd: number;
	newStart: number;
	newEnd: number;
}


/**
 * Implements a polynomial rolling hash for efficient substring searching.
 * This is used to quickly find potential matching blocks (anchors)
 * between two sequences of tokens.
 * @internal
 */
class RollingHash {
	private readonly P = 31; // A prime number for the polynomial hash
	private readonly M = 1e9 + 9; // A large prime modulus
	private readonly P_POW: number;
	private currentHash = 0;
	private readonly tokens: Uint32Array;
	private readonly length: number;

	/**
	 * Creates an instance of RollingHash.
	 * @param tokens - The array of token IDs to hash.
	 * @param length - The length of the window for hashing.
	 */
	constructor(tokens: Uint32Array, length: number) {
		this.tokens = tokens;
		this.length = length;
		this.P_POW = this._power(this.P, this.length - 1);
		this.currentHash = this._calculateInitialHash();
	}

	/**
	 * Gets the current hash value of the window.
	 * @returns The hash value.
	 */
	public getHash(): number {
		return this.currentHash;
	}

	/**
	 * Slides the hashing window one position to the right.
	 * It efficiently updates the hash value without recalculating from scratch
	 * by removing the leftmost token and adding the new rightmost token.
	 * @param oldToken - The token ID leaving the window.
	 * @param newToken - The token ID entering the window.
	 */
	public slide(oldToken: number, newToken: number): void {
		const M = this.M;
		const P = this.P;
		const P_POW = this.P_POW;

		// Remove the old token's contribution
		let hash = this.currentHash - (oldToken * P_POW) % M;
		if (hash < 0) hash += M;

		// Shift the hash to the left
		hash = (hash * P) % M;

		// Add the new token's contribution
		hash += newToken;
		if (hash >= M) hash -= M;

		this.currentHash = hash;
	}

	/**
	 * Calculates modular exponentiation (a^b % M).
	 * @param a - The base.
	 * @param b - The exponent.
	 * @returns The result of (a^b % M).
	 */
	private _power(a: number, b: number): number {
		const M = this.M;
		let res = 1;
		a %= M;

		while (b > 0) {
			if (b & 1) res = (res * a) % M;
			a = (a * a) % M;
			b >>= 1; // Faster than Math.floor(b / 2)
		}
		return res;
	}

	/**
	 * Calculates the initial hash for the first window of tokens.
	 * @returns The initial hash value.
	 */
	private _calculateInitialHash(): number {
		const M = this.M;
		const P = this.P;
		const tokens = this.tokens;
		const length = this.length;

		let hash = 0;
		for (let i = 0; i < length; i++) {
			hash = (hash * P + tokens[i]) % M;
		}
		return hash;
	}
}

/**
 * An advanced, high-performance implementation of the Myers diff algorithm.
 *
 * [v6.0] This class is implemented as an "Engine" (Toolbox) and a "Dispatcher".
 * It provides a "Toolbox" of core diffing algorithms (e.g., _findAnchors,
 * _recursiveDiff) and a "Registry" for "Strategy Plugins".
 *
 * The `diff()` method is a "Dispatcher" that performs tokenization and trimming,
 * then delegates the core diffing logic to the selected "Strategy Plugin"
 * (e.g., 'commonSES' or an external 'preserveStructure' plugin).
 *
 * ### Key Features & Techniques
 *
 * - **Token-Based Approach**: (Core) Converts string tokens to integer IDs
 * for blazing-fast comparisons.
 *
 * - **Prefix/Suffix Trimming**: (Core) Strips common prefixes and suffixes
 * before diffing.
 *
 * - **Strategy Registry (Plugins)**: Allows external code to register new
 * diffing strategies (e.G., `registerStrategy('preserveStructure', ...)`).
 * This makes the engine highly extensible for specialized tasks (like
 * genetic analysis) without modifying the core.
 *
 * - **Toolbox of Algorithms**: Provides all core algorithms as public methods
 * (e.g., `_findAnchors`, `_recursiveDiff`, `_guidedCalculateDiff`) for use
 * by external strategy plugins.
 *
 * ### Default Strategy: 'commonSES'
 *
 * The default built-in strategy, 'commonSES', implements the logic
 * optimized for finding the Shortest Edit Script (SES):
 *
 * - **Anchor-Based Guided Diff**: Uses `_findAnchors` (L1) to find
 * global floating anchors.
 * - **Recursive Myers**: Uses `_recursiveDiff` (with "middle snake")
 * to process the "gaps" between anchors, falling back to
 * `_guidedCalculateDiff` for very large gaps.
 *
 * @example
 * ```typescript
 * // 1. Using the default 'commonSES' strategy
 * const differ = new MyersCoreDiff();
 * const result = differ.diff(oldCode, newCode);
 *
 * // 2. Using a custom (externally registered) strategy
 * // (Assuming 'preserveStructure' was registered)
 * const options = { diffStrategyName: 'preserveStructure' };
 * const result = differ.diff(oldCode, newCode, false, options);
 * ```
 */
export class MyersCoreDiff {

	declare static __DEV__: boolean;

	private static strategyRegistry = new Map<string, DiffStrategyPlugin>();
    private static isDefaultRegistered = false;

	public static readonly defaultOptions: Required<DiffOptions> = {
		diffStrategyName: 'commonSES', // [v6.0] Default strategy
		minMatchLength: 30,
		quickDiffThreshold: 64,
		hugeDiffThreshold: 256,
		lookahead: 10,
		corridorWidth: 10,
		skipTrimming: false,
		jumpStep: 30,
		huntChunkSize: 10,
		minAnchorConfidence: 0.8,
		useAnchors: true,
		localgap: 10,
		preservePositions: true, // Default for 'commonSES'
		localLookahead: 50,
		anchorSearchMode: 'combo',
		positionalAnchorMaxDrift: 20,
	};

	private static ensureDefaultStrategyRegistered(instance: MyersCoreDiff): void {
        // Register only if the flag is not set
        if (!MyersCoreDiff.isDefaultRegistered) {
            // Use the passed instance to correctly bind 'this' for the method
            MyersCoreDiff.registerStrategy('commonSES', instance._strategycommonSES.bind(instance));
            MyersCoreDiff.isDefaultRegistered = true; // Set the flag
             if (__DEV__) {
                console.log(`[MyersCoreDiff Static] Registered default 'commonSES' strategy.`);
            }
        }
    }
	

	/**
	 * [v6.0] Registers a new diffing strategy plugin with the Core Engine.
	 * @param name The name of the strategy (e.g., 'preserveStructure').
	 * @param strategyFn The function implementing the DiffStrategyPlugin interface.
	 */
	public static registerStrategy(name: string, strategyFn: DiffStrategyPlugin): void {
		if (__DEV__) {
			console.log(`[MyersCoreDiff] Registering strategy: '${name}'`);
		}
		MyersCoreDiff.strategyRegistry.set(name, strategyFn);
	}

	/**
	 * [v6.0] Initializes the Core Engine and registers built-in strategies.
	 */
	constructor() {
		MyersCoreDiff.ensureDefaultStrategyRegistered(this);
	}

	/**
	 * [v6.0] Computes the difference using the "Dispatcher" logic.
	 *
	 * This method performs setup (tokenization, trimming) and then delegates
	 * the core diffing logic to the selected "Strategy Plugin" from the
	 * registry (based on `options.diffStrategyName`).
	 *
	 * @param oldTokens - The original array of strings.
	 * @param newTokens - The new array of strings.
	 * @param debug - (Internal) Enables verbose logging for debugging purposes.
	 * @param options - Optional configuration, including `diffStrategyName`.
	 * @returns An array of DiffResult tuples representing the edit script.
	 */
	public diff(
		oldTokens: string[],
		newTokens: string[],
		debug: boolean = false,
		options?: DiffOptions
	): DiffResult[] {
		const config: Required<DiffOptions> = {
			...MyersCoreDiff.defaultOptions,
			...options,
		};

		

		if (__DEV__ && debug) {
			console.group(`[diff] START (Dispatcher)`);
			console.log(`Options:`, config);
		}

		// --- 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ (–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –¢—Ä–∏–º–º–∏–Ω–≥) ---
		const { hashedOld, hashedNew, idToString } = this._tokenize(oldTokens, newTokens, debug);

		let prefix: DiffResult[] = [];
		let suffix: DiffResult[] = [];
		let newOldStart = 0;
		let newOldEnd = hashedOld.length;
		let newNewStart = 0;
		let newNewEnd = hashedNew.length;

		if (!config.skipTrimming) {
			const trimmed = this._trimCommonPrefixSuffix(
				hashedOld, 0, hashedOld.length,
				hashedNew, 0, hashedNew.length,
				idToString
			);
			prefix = trimmed.prefix;
			suffix = trimmed.suffix;
			newOldStart = trimmed.newOldStart;
			newOldEnd = trimmed.newOldEnd;
			newNewStart = trimmed.newNewStart;
			newNewEnd = trimmed.newNewEnd;
		}

		// --- 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ ---
		const strategyName = config.diffStrategyName;

		if (__DEV__ && debug) {
			console.log(`[diff] Dispatching to strategy: '${strategyName}'`);
		}

		// --- 3. –ü–æ–∏—Å–∫ –ü–ª–∞–≥–∏–Ω–∞ ---
		const strategyFn = MyersCoreDiff.strategyRegistry.get(strategyName);

		if (!strategyFn) {
			throw new Error(`[MyersCoreDiff] –°—Ç—Ä–∞—Ç–µ–≥–∏—è '${strategyName}' –Ω–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∞.`);
		}

		// --- 4. –í—ã–∑–æ–≤ –ü–ª–∞–≥–∏–Ω–∞ (–ø–µ—Ä–µ–¥–∞–µ–º 'this' –∫–∞–∫ "–î–≤–∏–∂–æ–∫") ---
		const body = strategyFn(
			this, // –ò–Ω—Å—Ç–∞–Ω—Å "–î–≤–∏–∂–∫–∞"
			hashedOld, newOldStart, newOldEnd,
			hashedNew, newNewStart, newNewEnd,
			idToString, config, debug
		);

		// --- 5. –°–±–æ—Ä–∫–∞ ---
		if (__DEV__ && debug) {
			console.log(`[diff] FINISH (Dispatcher). Total result length: ${prefix.length + body.length + suffix.length}`);
			console.groupEnd();
		}

		return prefix.concat(body).concat(suffix);
	}

	/**
     * [v6.1 - Corrected] Built-in plugin strategy "commonSES".
     * Implements the classic cdiff logic optimized for SES,
     * but *retains* the ability to use _calculateStableDiff if
     * config.preservePositions is true (preserving original behavior).
     */
	private _strategycommonSES(
        engine: MyersCoreDiff, // engine parameter is convention, 'this' is used internally
        oldTokens: Uint32Array, oldStart: number, oldEnd: number,
        newTokens: Uint32Array, newStart: number, newEnd: number,
        idToString: string[],
        config: Required<DiffOptions>, // Config includes preservePositions
        debug: boolean
    ): DiffResult[] {

        if (__DEV__ && debug) {
            console.group(`[Strategy 'commonSES' v1 LOGIC] START old[${oldStart},${oldEnd}) new[${newStart},${newEnd})`);
            console.log(`Config:`, config);
        }

        const lakeSize = (oldEnd - oldStart) + (newEnd - newStart);

        // --- Anchor Finding (Logic from v1 diff) ---
        let anchors: Anchor[] = [];
        if (config.useAnchors && lakeSize > config.quickDiffThreshold) {
            // Use 'this' (engine instance) to call toolbox methods
            const foundAnchors = this._findAnchors(
                oldTokens, oldStart, oldEnd,
                newTokens, newStart, newEnd,
                config, debug
            );

            // Filter anchors (Logic from v1 diff)
            anchors = this._mergeAndFilterAnchors(foundAnchors, config, debug);

            if (anchors.length === 0 && __DEV__ && debug) {
                console.log(`[Strategy 'commonSES' v1 LOGIC] No valid anchor chain found - falling back to pure diff`);
            }
        }

        let body: DiffResult[] = [];

        // --- Branching Logic (Logic from v1 diff) ---
        if (anchors.length > 0) {
            // Use anchors path
             if (__DEV__ && debug) {
                 console.log(`[Strategy 'commonSES' v1 LOGIC] Using anchors path (_processWithAnchors)`);
             }
            body = this._processWithAnchors( // Use 'this'
                oldTokens, oldStart, oldEnd,
                newTokens, newStart, newEnd,
                anchors, idToString, config, debug, 0 // depth=0
            );
        } else {
            // Pure diff path (no anchors)
            if (config.preservePositions) {
                // Use stable diff path
                if (__DEV__ && debug) {
                    console.log(`[Strategy 'commonSES' v1 LOGIC] No anchors, using stable diff path (_calculateStableDiff)`);
                }
                body = this._calculateStableDiff( // Use 'this'
                    oldTokens, oldStart, oldEnd,
                    newTokens, newStart, newEnd,
                    idToString, config, debug
                );
            } else {
                // Use recursive SES path
                 if (__DEV__ && debug) {
                     console.log(`[Strategy 'commonSES' v1 LOGIC] No anchors, using recursive SES path (_recursiveDiff)`);
                 }
                body = this._recursiveDiff( // Use 'this'
                    oldTokens, oldStart, oldEnd,
                    newTokens, newStart, newEnd,
                    idToString, config, debug
                );
            }
        }

        if (__DEV__ && debug) {
            console.log(`[Strategy 'commonSES' v1 LOGIC] END. Body length: ${body.length}`);
            console.groupEnd();
        }
        return body;
    }

	/**
	 * [v6.0] Finds anchors (significant matching blocks) between old and new token sequences.
	 * These anchors help guide the diffing process by identifying stable regions.
	 * @param oldTokens - The original array of token IDs.
	 * @param oldStart - The starting index in the oldTokens array.
	 * @param oldEnd - The ending index (exclusive) in the oldTokens array.
	 * @param newTokens - The new array of token IDs.
	 * @param newStart - The starting index in the newTokens array.
	 * @param newEnd - The ending index (exclusive) in the newTokens array.
	 * @param config - The diff options configuration.
	 * @param debug - Enables verbose logging for debugging purposes.
	 * @returns An array of Anchor objects representing the found anchors.
	 */

	public _findAnchors(
        oldTokens: Uint32Array, oldStart: number, oldEnd: number,
        newTokens: Uint32Array, newStart: number, newEnd: number,
        config: Required<DiffOptions>, // –í–∫–ª—é—á–∞–µ—Ç anchorSearchMode –∏ positionalAnchorMaxDrift
        debug: boolean
    ): Anchor[] {
        // --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ ---
        const anchorSearchMode = config.anchorSearchMode ?? 'combo'; // –†–µ–∂–∏–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        const maxDrift = config.positionalAnchorMaxDrift; // –ü–æ—Ä–æ–≥ –¥–ª—è –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã—Ö
        const { jumpStep, huntChunkSize, minMatchLength, minAnchorConfidence } = config; // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞

        if (__DEV__ && debug) {
            console.log(`\n--- [_findAnchors v6.4 START with FILTERING] ---`);
            console.log(`Filter Mode: ${anchorSearchMode}, PositionalMaxDrift: ${maxDrift}`);
            console.log(`Search Params: jump=${jumpStep}, chunk=${huntChunkSize}, minLen=${minMatchLength}, minConf=${minAnchorConfidence}`);
            console.log(`Lake: old[${oldStart}, ${oldEnd}) new[${newStart}, ${newEnd})`);
        }

        const lakeOldLen = oldEnd - oldStart;
        const lakeNewLen = newEnd - newStart;

        // –ê–≤—Ç–æ–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –æ–∑–µ—Ä
        if (lakeOldLen + lakeNewLen < config.quickDiffThreshold) {
            if (__DEV__ && debug) console.log(`[_findAnchors] Skipping - lake too small (${lakeOldLen + lakeNewLen} < ${config.quickDiffThreshold}).`);
            return [];
        }
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ–∏—Å–∫–∞
        if (huntChunkSize <= 0 || minMatchLength < huntChunkSize) {
             if (__DEV__ && debug) console.log(`[_findAnchors] Skipping - invalid params (huntChunkSize=${huntChunkSize}, minMatchLength=${minMatchLength}).`);
             return [];
        }

        const anchors: Anchor[] = []; // –ú–∞—Å—Å–∏–≤ –¥–ª—è —Å–±–æ—Ä–∞ –í–°–ï–• –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —è–∫–æ—Ä–µ–π
        const usedNewPos = new Uint8Array(newTokens.length); // –ï–¥–∏–Ω–∞—è –º–∞—Å–∫–∞ –¥–ª—è newTokens

        // --- –û—Å–Ω–æ–≤–Ω–æ–π –ü–æ–∏—Å–∫ (–†–æ–ª–ª–∏–Ω–≥-—Ö—ç—à + –û—Ö–æ—Ç–∞) ---
        const newHashes = new Map<number, { pos: number }[]>();
        const rh = new RollingHash(new Uint32Array(0), 0);
        const newLen = newEnd - newStart;

        // –°—Ç—Ä–æ–∏–º —Ö—ç—à-—Ç–∞–±–ª–∏—Ü—É –¥–ª—è newTokens
        if (newLen >= huntChunkSize) {
            for (let i = 0; i <= newLen - huntChunkSize; i += 1) {
                const pos = newStart + i;
                const slice = newTokens.subarray(pos, pos + huntChunkSize);
                let hash = 0;
                for (let k = 0; k < slice.length; k++) hash = (hash * rh['P'] + slice[k]) % rh['M'];
                if (!newHashes.has(hash)) newHashes.set(hash, []);
                newHashes.get(hash)!.push({ pos });
            }
        }

        if (newHashes.size === 0) {
             if (__DEV__ && debug) console.log(`[_findAnchors] Hash map empty. No potential anchors.`);
        } else {
             if (__DEV__ && debug) console.log(`[_findAnchors] Built hash map with ${newHashes.size} unique chunks. Searching old tokens...`);

            // –ò—â–µ–º –≤ oldTokens
            for (let i = 0; i <= lakeOldLen - huntChunkSize; i += jumpStep) {
                const oldPos = oldStart + i;
                const slice = oldTokens.subarray(oldPos, oldPos + huntChunkSize);
                let hash = 0;
                for (let k = 0; k < slice.length; k++) hash = (hash * rh['P'] + slice[k]) % rh['M'];
                const potentialStarts = newHashes.get(hash);
                if (!potentialStarts) continue;

                for (const start of potentialStarts) {
                    if (usedNewPos[start.pos]) continue; // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –≤ new

                    // --- –û—Ö–æ—Ç–∞ (Hunting) ---
                    const foundFragments: { oldPos: number; newPos: number }[] = [{ oldPos, newPos: start.pos }];
                    let currentHuntOldPos = oldPos + huntChunkSize;
                    const maxHuntJumps = 10;
                    let successfulHunts = 1;
                    for (let chunkNum = 1; chunkNum * huntChunkSize < minMatchLength; chunkNum++) {
                        let chunkFound = false;
                        const lastFragment = foundFragments[foundFragments.length - 1];
                        for (let j = 0; j < maxHuntJumps; j++) {
                            const nextOldPos = currentHuntOldPos + j * jumpStep;
                            if (nextOldPos + huntChunkSize > oldEnd) break;
                            const nextSlice = oldTokens.subarray(nextOldPos, nextOldPos + huntChunkSize);
                            let nextHash = 0;
                            for (let k = 0; k < nextSlice.length; k++) nextHash = (nextHash * rh['P'] + nextSlice[k]) % rh['M'];
                            const potentialMatches = newHashes.get(nextHash);
                            if (potentialMatches) {
                                for (const match of potentialMatches) {
                                    if (match.pos > lastFragment.newPos && !usedNewPos[match.pos]) {
                                        foundFragments.push({ oldPos: nextOldPos, newPos: match.pos });
                                        currentHuntOldPos = nextOldPos + huntChunkSize;
                                        chunkFound = true; successfulHunts++;
                                        break;
                                    }
                                }
                            }
                            if (chunkFound) break;
                        }
                        if (!chunkFound) break;
                    } // --- –ö–æ–Ω–µ—Ü –û—Ö–æ—Ç—ã ---

                    const huntConfidence = (successfulHunts * huntChunkSize) / minMatchLength;

                    // --- –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ ---
                    if (huntConfidence >= minAnchorConfidence) {
                        const firstFrag = foundFragments[0];
                        let finalLength = 0;
                        const scanOldStart = firstFrag.oldPos;
                        const scanNewStart = firstFrag.newPos;
                        // –†–∞—Å—à–∏—Ä—è–µ–º, –ø–æ–∫–∞ —Å–æ–≤–ø–∞–¥–∞—é—Ç –∏ –Ω–µ –∑–∞–Ω—è—Ç—ã –≤ new
                        while (
                            scanOldStart + finalLength < oldEnd &&
                            scanNewStart + finalLength < newEnd &&
                            !usedNewPos[scanNewStart + finalLength] && // –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞—Å–∫—É –ø—Ä–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏
                            oldTokens[scanOldStart + finalLength] === newTokens[scanNewStart + finalLength]
                        ) {
                            finalLength++;
                        }

                        // --- –°–æ–∑–¥–∞–Ω–∏–µ –Ø–∫–æ—Ä—è ---
                        if (finalLength >= minMatchLength) {
                            const driftDistance = Math.abs(scanNewStart - scanOldStart);
                            const driftRatio = finalLength > 0 ? driftDistance / finalLength : 0;
                            // –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —è–∫–æ—Ä—è (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
                            const maxExpectedDrift = Math.max(100, Math.min(lakeOldLen, lakeNewLen) * 0.1);
                            const driftConf = Math.max(0, 1.0 - (driftDistance / maxExpectedDrift)); // –ò—Å–ø–æ–ª—å–∑—É–µ–º Math.max –¥–ª—è >= 0
                            const lengthConf = Math.min(1.0, finalLength / (minMatchLength * 2));
                            const anchorConfidence = (driftConf * 0.3 + lengthConf * 0.7); // –§–∏–Ω–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å

                            // –î–æ–±–∞–≤–ª—è–µ–º —è–∫–æ—Ä—å –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
                            const anchor: Anchor = {
                                oldPos: scanOldStart, newPos: scanNewStart, length: finalLength,
                                confidence: anchorConfidence, driftDistance, driftRatio
                            };
                            anchors.push(anchor);

                            // –ü–æ–º–µ—á–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ new
                            for (let k = 0; k < finalLength; k++) {
                                if (scanNewStart + k < newTokens.length) usedNewPos[scanNewStart + k] = 1;
                            }
                            // –ü–µ—Ä–µ–ø—Ä—ã–≥–∏–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π –±–ª–æ–∫ –≤ old
                            i = (scanOldStart - oldStart) + finalLength - jumpStep;
                             if (__DEV__ && debug) console.log(`  -> ANCHOR FOUND: old=${scanOldStart}, new=${scanNewStart}, len=${finalLength}, drift=${driftDistance}, conf=${anchorConfidence.toFixed(2)}. Jumping i to ${i + jumpStep}`);
                            break; // –ü—Ä–µ—Ä—ã–≤–∞–µ–º –ø–æ–∏—Å–∫ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ oldPos, —Ç.–∫. –Ω–∞—à–ª–∏ —è–∫–æ—Ä—å
                        } // --- –ö–æ–Ω–µ—Ü –°–æ–∑–¥–∞–Ω–∏—è –Ø–∫–æ—Ä—è ---
                    } // --- –ö–æ–Ω–µ—Ü –í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ ---
                } // end loop potentialStarts
            } // end loop oldTokens
        } // --- –ö–æ–Ω–µ—Ü –û—Å–Ω–æ–≤–Ω–æ–≥–æ –ü–æ–∏—Å–∫–∞ ---

        if (__DEV__ && debug) console.log(`[_findAnchors] Initial search found ${anchors.length} raw anchors.`);

        // --- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ç–∏–ø—É (anchorSearchMode) ---
        let filteredByTypeAnchors: Anchor[];
        if (anchorSearchMode === 'positional') {
            filteredByTypeAnchors = anchors.filter(a => a.driftDistance <= maxDrift);
            if (__DEV__ && debug) console.log(`  Filtered for 'positional' (drift <= ${maxDrift}): ${filteredByTypeAnchors.length} anchors remaining.`);
        } else if (anchorSearchMode === 'floating') {
            filteredByTypeAnchors = anchors.filter(a => a.driftDistance > maxDrift);
             if (__DEV__ && debug) console.log(`  Filtered for 'floating' (drift > ${maxDrift}): ${filteredByTypeAnchors.length} anchors remaining.`);
        } else { // 'combo' or default
            filteredByTypeAnchors = anchors; // –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ
             if (__DEV__ && debug) console.log(`  Mode 'combo', using all ${filteredByTypeAnchors.length} anchors for confidence check.`);
        }

        // --- –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ Confidence ---
        const finalAnchors = filteredByTypeAnchors.filter(anchor => anchor.confidence >= minAnchorConfidence);

        if (__DEV__ && debug) {
            console.log(`  Filtered by confidence >= ${minAnchorConfidence}: ${finalAnchors.length} anchors remaining.`);
            console.log(`--- [_findAnchors v6.4 END] Returning ${finalAnchors.length} anchors ---`);
        }

        return finalAnchors; // –í–æ–∑–≤—Ä–∞—â–∞–µ–º —è–∫–æ—Ä—è, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø—É –ò –ø–æ confidence
    }


	/**
	 * [TOOLBOX] Merges anchors, filters conflicts, and sorts them
	 * to produce a final, monotonic chain.
	 */
	public _mergeAndFilterAnchors(
		anchors: Anchor[],
		config: Required<DiffOptions>,
		debug: boolean
	): Anchor[] {
		if (__DEV__ && debug) {
			console.log(`\n--- [_mergeAndFilterAnchors START] ---`);
			console.log(`Input anchors: ${anchors.length}`);
		}

		if (anchors.length === 0) return [];

		// –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ oldPos
		anchors.sort((a, b) => a.oldPos - b.oldPos);

		const n = anchors.length;
		const dp = new Array(n).fill(0);
		const prev = new Array(n).fill(-1);

		// –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ü–µ–ø–∏
		for (let i = 0; i < n; i++) {
			const anchorI = anchors[i];
			dp[i] = anchorI.length;

			for (let j = 0; j < i; j++) {
				const anchorJ = anchors[j];

				// –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –æ–∑–µ—Ä
				const noOverlap = (anchorI.oldPos >= anchorJ.oldPos + anchorJ.length) &&
					(anchorI.newPos >= anchorJ.newPos + anchorJ.length);

				if (noOverlap) {
					// –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç–∏
					const monotoneInOld = anchorI.oldPos > anchorJ.oldPos;
					const monotoneInNew = anchorI.newPos > anchorJ.newPos;

					if (monotoneInOld || monotoneInNew) {
						if (dp[j] + anchorI.length > dp[i]) {
							dp[i] = dp[j] + anchorI.length;
							prev[i] = j;
						}
					}
				}
			}
		}

		// –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Ü–µ–ø—å
		let bestChainEndIndex = 0;
		for (let i = 1; i < n; i++) {
			if (dp[i] > dp[bestChainEndIndex]) {
				bestChainEndIndex = i;
			}
		}

		const optimalChain: Anchor[] = [];
		let currentIndex = bestChainEndIndex;
		while (currentIndex !== -1) {
			optimalChain.push(anchors[currentIndex]);
			currentIndex = prev[currentIndex];
		}
		optimalChain.reverse();

		// –í–ê–õ–ò–î–ê–¶–ò–Ø: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ü–µ–ø—å –Ω–µ —Å–æ–∑–¥–∞—Å—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –æ–∑–µ—Ä
		for (let i = 1; i < optimalChain.length; i++) {
			const prevAnchor = optimalChain[i - 1];
			const currAnchor = optimalChain[i];

			const gapOld = currAnchor.oldPos - (prevAnchor.oldPos + prevAnchor.length);
			const gapNew = currAnchor.newPos - (prevAnchor.newPos + prevAnchor.length);

			if (gapOld < 0 || gapNew < 0) {
				if (__DEV__ && debug) {
					console.error(`‚ùå INVALID CHAIN: Negative gap detected between anchors`);
					console.error(`   Anchor ${i - 1}: old[${prevAnchor.oldPos}, ${prevAnchor.oldPos + prevAnchor.length}) new[${prevAnchor.newPos}, ${prevAnchor.newPos + prevAnchor.length})`);
					console.error(`   Anchor ${i}: old[${currAnchor.oldPos}, ${currAnchor.oldPos + currAnchor.length}) new[${currAnchor.newPos}, ${currAnchor.newPos + currAnchor.length})`);
					console.error(`   Gaps: old=${gapOld}, new=${gapNew}`);
				}
				// –í —Å–ª—É—á–∞–µ –ø—Ä–æ–±–ª–µ–º—ã –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Ü–µ–ø—å - –ª—É—á—à–µ –±–µ–∑ —è–∫–æ—Ä–µ–π —á–µ–º —Å –æ—à–∏–±–∫–æ–π
				return [];
			}
		}

		if (__DEV__ && debug) {
			console.log(`--- [_mergeAndFilterAnchors END] Optimal chain: ${optimalChain.length} anchors ---\n`);
		}

		return optimalChain;
	}


	/**
	 * [TOOLBOX] Processes the diff by iterating through the anchor chain
	 * and calling `_processGap` for regions between them.
	 */
	public _processWithAnchors(
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		anchors: Anchor[],
		idToString: string[],
		config: Required<DiffOptions>,
		debug: boolean,
		depth: number = 0
	): DiffResult[] {
		if (__DEV__ && debug) {
			console.log('--- [_processWithAnchors START] ---');
			console.group(`[Phase 2] _processWithAnchors (depth=${depth})`);
			console.log(`Input ranges: old [${oldStart}, ${oldEnd}) | new [${newStart}, ${newEnd})`);
			console.log(`Anchors count: ${anchors.length}`);
			console.log(`Config:`, config);

			const oldSegment = Array.from(oldTokens.slice(oldStart, oldEnd)).map(id => idToString[id]);
			const newSegment = Array.from(newTokens.slice(newStart, newEnd)).map(id => idToString[id]);
			console.log(`Old segment tokens:`, oldSegment);
			console.log(`New segment tokens:`, newSegment);
		}

		if (oldStart > oldEnd || newStart > newEnd) {
			console.error(`‚ùå INVALID RANGES in _processWithAnchors: old[${oldStart}, ${oldEnd}) new[${newStart}, ${newEnd})`);
			return this._processGap(
				{ oldStart, oldEnd, newStart, newEnd },
				oldTokens, newTokens, idToString, config, debug
			);
		}

		if (anchors.length === 0) {
			if (__DEV__ && debug) {
				console.log(`[Phase 2] No anchors found ‚Äî delegating to _processGap`);
				console.groupEnd();
			}
			return this._processGap(
				{ oldStart, oldEnd, newStart, newEnd },
				oldTokens, newTokens,
				idToString, config, debug
			);
		}

		const result: DiffResult[] = [];
		let currentOldPos = oldStart;
		let currentNewPos = newStart;

		for (let index = 0; index < anchors.length; index++) {
			const anchor = anchors[index];
			if (__DEV__ && debug) {
				console.group(`[Anchor ${index}] oldPos=${anchor.oldPos}, newPos=${anchor.newPos}, length=${anchor.length}`);
			}

			// Process gap before anchor if any
			if (anchor.oldPos > currentOldPos || anchor.newPos > currentNewPos) {
				if (__DEV__ && debug) {
					console.log(`[Anchor ${index}] Detected gap before anchor.`);
				}
				const gapResult = this._processGap(
					{
						oldStart: currentOldPos, oldEnd: anchor.oldPos,
						newStart: currentNewPos, newEnd: anchor.newPos
					},
					oldTokens, newTokens, idToString, config, debug
				);
				if (__DEV__ && debug) {
					console.log(`[Anchor ${index}] Gap result:`, gapResult);
				}
				for (let i = 0; i < gapResult.length; i++) {
					result.push(gapResult[i]);
				}
			}

			// Add anchor equal sequence
			const equalTokens: string[] = [];
			for (let j = 0; j < anchor.length; j++) {
				const tokenStr = idToString[oldTokens[anchor.oldPos + j]];
				equalTokens.push(tokenStr);
				result.push([DiffOperation.EQUAL, tokenStr]);
			}
			if (__DEV__ && debug) {
				console.log(`[Anchor ${index}] Equal sequence:`, equalTokens);
			}

			currentOldPos = anchor.oldPos + anchor.length;
			currentNewPos = anchor.newPos + anchor.length;

			if (__DEV__ && debug) {
				console.groupEnd();
			}
		}

		// Handle trailing gap after last anchor
		if (currentOldPos < oldEnd || currentNewPos < newEnd) {
			if (__DEV__ && debug) {
				console.group(`[Final gap] old [${currentOldPos}, ${oldEnd}), new [${currentNewPos}, ${newEnd})`);
			}
			const finalGapResult = this._processGap(
				{
					oldStart: currentOldPos, oldEnd: oldEnd,
					newStart: currentNewPos, newEnd: newEnd
				},
				oldTokens, newTokens, idToString, config, debug
			);
			if (__DEV__ && debug) {
				console.log(`[Final gap] Result:`, finalGapResult);
				console.groupEnd();
			}
			for (let i = 0; i < finalGapResult.length; i++) {
				result.push(finalGapResult[i]);
			}
		}

		if (__DEV__ && debug) {
			console.log(`[Phase 2] Final diff result:`, result);
			console.groupEnd();
		}

		return result;
	}


	/**
	 * [TOOLBOX] A dispatcher that chooses the appropriate diffing strategy
	 * for a gap, optimized for 'commonSES' (SES).
	 */
	public _processGap(
		gap: GapInfo,
		oldTokens: Uint32Array,
		newTokens: Uint32Array,
		idToString: string[],
		config: Required<DiffOptions>,
		debug: boolean
	): DiffResult[] {
		const gapOldLen = gap.oldEnd - gap.oldStart;
		const gapNewLen = gap.newEnd - gap.newStart;
		const gapSize = gapOldLen + gapNewLen;

		if (__DEV__ && debug) {
			console.log(`[_processGap] Processing gap. size=${gapSize} (old=${gapOldLen}, new=${gapNewLen})`);
		}

		if (gapSize === 0) {
			return [];
		}

		const sizeRatio = gapOldLen > 0 && gapNewLen > 0
			? Math.max(gapOldLen / gapNewLen, gapNewLen / gapOldLen)
			: 0;

		if (sizeRatio > 100 && gapSize > 500) {
			if (__DEV__ && debug) {
				console.log(`[_processGap] Absurd case detected. Using simple add/remove.`);
			}
			const deletions = this._createDeletions(oldTokens, gap.oldStart, gap.oldEnd, idToString);
			const additions = this._createAdditions(newTokens, gap.newStart, gap.newEnd, idToString);
			deletions.push.apply(deletions, additions);
			return deletions;
		}

		if (gapSize > config.hugeDiffThreshold) {
			if (__DEV__ && debug) {
				console.log(`[_processGap] Gap size is huge (${gapSize}), falling back to guided diff for performance.`);
			}
			return this._guidedCalculateDiff(
				oldTokens, gap.oldStart, gap.oldEnd,
				newTokens, gap.newStart, gap.newEnd,
				idToString, config, debug
			);
		}

		if (__DEV__ && debug) {
			console.log(`[_processGap] Gap size is manageable (${gapSize}), using precise recursive Myers diff.`);
		}
		return this._recursiveDiff(
			oldTokens, gap.oldStart, gap.oldEnd,
			newTokens, gap.newStart, gap.newEnd,
			idToString, config, debug
		);
	}

	/**
	 * [TOOLBOX] The core recursive implementation of the Myers diff algorithm
	 * with the "middle snake" optimization (SES).
	 */
	public _recursiveDiff(
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		idToString: string[],
		config: Required<DiffOptions>,
		debug: boolean
	): DiffResult[] {
		if (__DEV__ && debug) {
			console.group(`[recursiveDiff] START old[${oldStart}, ${oldEnd}) new[${newStart}, ${newEnd})`);
		}

		const oldLen = oldEnd - oldStart;
		const newLen = newEnd - newStart;

		if (oldLen < 0 || newLen < 0) {
			if (__DEV__ && debug) {
				console.error(`[recursiveDiff] ‚ùå NEGATIVE LENGTH at entry! oldLen=${oldLen}, newLen=${newLen}`);
				console.error(`  oldStart=${oldStart}, oldEnd=${oldEnd}, newStart=${newStart}, newEnd=${newEnd}`);
			}
			throw new Error(`Negative length detected at recursiveDiff entry`);
		}

		if (oldLen === 0 && newLen === 0) {
			if (__DEV__ && debug) console.groupEnd();
			return [];
		}
		if (oldLen === 0) {
			if (__DEV__ && debug) console.log(`[recursiveDiff] Old length = 0 ‚Üí ADDITIONS`);
			const res = this._createAdditions(newTokens, newStart, newEnd, idToString);
			if (__DEV__ && debug) {
				console.log(`[recursiveDiff] Additions result:`, res);
				console.groupEnd();
			}
			return res;
		}
		if (newLen === 0) {
			if (__DEV__ && debug) console.log(`[recursiveDiff] New length = 0 ‚Üí DELETIONS`);
			const res = this._createDeletions(oldTokens, oldStart, oldEnd, idToString);
			if (__DEV__ && debug) {
				console.log(`[recursiveDiff] Deletions result:`, res);
				console.groupEnd();
			}
			return res;
		}

		if ((oldLen + newLen) < config.quickDiffThreshold) {
			if (__DEV__ && debug) {
				console.log(`[recursiveDiff] Using quick diff: (oldLen+newLen)=${oldLen + newLen} < ${config.quickDiffThreshold}`);
			}
			const res = this.calculateDiff(
				oldTokens, oldStart, oldEnd,
				newTokens, newStart, newEnd,
				idToString, config, debug
			);
			if (__DEV__ && debug) {
				console.log(`[recursiveDiff] Quick diff result:`, res);
				console.groupEnd();
			}
			return res;
		}

		// --- FIND MIDDLE SNAKE ---
		const snake = this._findMiddleSnake(oldTokens, oldStart, oldEnd, newTokens, newStart, newEnd, debug);

		if (__DEV__ && debug) {
			console.log(`[recursiveDiff] Middle snake:`, snake);
		}

		if (!snake || snake.u - snake.x <= 0) {
			if (__DEV__ && debug) {
				console.warn(`[recursiveDiff] Middle snake failed, falling back to _guidedCalculateDiff`);
			}
			const res = this._guidedCalculateDiff(
				oldTokens, oldStart, oldEnd,
				newTokens, newStart, newEnd,
				idToString, config, debug
			);
			// const res = this.calculateDiff(
			// 	oldTokens, oldStart, oldEnd,
			// 	newTokens, newStart, newEnd,
			// 	idToString, config, debug
			// );
			if (__DEV__ && debug) {
				console.log(`[recursiveDiff] Fallback result:`, res);
				console.groupEnd();
			}
			return res;
		}

		const snakeLen = snake.u - snake.x;

		// --- VALIDATE SNAKE ---
		for (let i = 0; i < snakeLen; i++) {
			const oldVal = oldTokens[oldStart + snake.x + i];
			const newVal = newTokens[newStart + snake.y + i];
			if (oldVal !== newVal) {
				if (__DEV__ && debug) {
					console.error(`  ‚ö†Ô∏è [recursiveDiff] SNAKE VALIDATION FAILED at i=${i}`);
					console.error(`    oldVal=${oldVal}(${idToString[oldVal]}), newVal=${newVal}(${idToString[newVal]})`);
				}
				const res = this.calculateDiff(
					oldTokens, oldStart, oldEnd,
					newTokens, newStart, newEnd,
					idToString, config, debug
				);
				if (__DEV__ && debug) {
					console.log(`[recursiveDiff] Fallback due to snake validation result:`, res);
					console.groupEnd();
				}
				return res;
			}
		}

		// --- RECURSION PART 1 ---
		const leftOldStart = oldStart;
		const leftOldEnd = oldStart + snake.x;
		const leftNewStart = newStart;
		const leftNewEnd = newStart + snake.y;

		if (leftOldEnd - leftOldStart < 0 || leftNewEnd - leftNewStart < 0) {
			if (__DEV__ && debug) {
				console.error(`[recursiveDiff] ‚ùå NEGATIVE LENGTH in LEFT part`);
				console.error(`  old [${leftOldStart}, ${leftOldEnd}), new [${leftNewStart}, ${leftNewEnd})`);
			}
			throw new Error(`Negative length detected in left recursive part`);
		}

		if (__DEV__ && debug) {
			console.log(`[recursiveDiff] ‚Üí Left recursion old[${leftOldStart}, ${leftOldEnd}) new[${leftNewStart}, ${leftNewEnd})`);
		}

		const part1 = this._recursiveDiff(
			oldTokens, leftOldStart, leftOldEnd,
			newTokens, leftNewStart, leftNewEnd,
			idToString, config, debug
		);

		// --- SNAKE PART ---
		const snakePart = new Array<DiffResult>(snakeLen);
		for (let i = 0; i < snakeLen; i++) {
			snakePart[i] = [DiffOperation.EQUAL, idToString[oldTokens[oldStart + snake.x + i]]];
		}
		if (__DEV__ && debug) {
			console.log(`[recursiveDiff] Snake part length=${snakeLen}`);
		}

		// --- RECURSION PART 2 ---
		const rightOldStart = oldStart + snake.u;
		const rightOldEnd = oldEnd;
		const rightNewStart = newStart + snake.v;
		const rightNewEnd = newEnd;

		if (rightOldEnd - rightOldStart < 0 || rightNewEnd - rightNewStart < 0) {
			if (__DEV__ && debug) {
				console.error(`[recursiveDiff] ‚ùå NEGATIVE LENGTH in RIGHT part`);
				console.error(`  old [${rightOldStart}, ${rightOldEnd}), new [${rightNewStart}, ${rightNewEnd})`);
			}
			throw new Error(`Negative length detected in right recursive part`);
		}

		if (__DEV__ && debug) {
			console.log(`[recursiveDiff] ‚Üí Right recursion old[${rightOldStart}, ${rightOldEnd}) new[${rightNewStart}, ${rightNewEnd})`);
		}

		const part2 = this._recursiveDiff(
			oldTokens, rightOldStart, rightOldEnd,
			newTokens, rightNewStart, rightNewEnd,
			idToString, config, debug
		);

		const result = part1.concat(snakePart, part2);

		if (__DEV__ && debug) {
			console.log(`[recursiveDiff] RETURN result length=${result.length}`);
			console.groupEnd();
		}

		return result;
	}


	/**
	 * [TOOLBOX] Finds the "middle snake" for linear-memory Myers.
	 */
	private forwardBuffer = new Int32Array(0);
	private backwardBuffer = new Int32Array(0);

	private _validateInputs(
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number
	): boolean {
		if (oldStart < 0 || oldEnd < oldStart || oldEnd > oldTokens.length) return false;
		if (newStart < 0 || newEnd < newStart || newEnd > newTokens.length) return false;
		return true;
	}

	public _findMiddleSnake(
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		debug: boolean
	): MiddleSnake | undefined {
		if (__DEV__ && debug) {
			console.log('[findMiddleSnake] START');
		}
		if (!this._validateInputs(oldTokens, oldStart, oldEnd, newTokens, newStart, newEnd)) {
			if (__DEV__ && debug) console.error('[findMiddleSnake] ‚ùå Invalid input ranges');
			return undefined;
		}

		const N = oldEnd - oldStart;
		const M = newEnd - newStart;
		const offset = N + M;
		const requiredSize = 2 * offset + 2;

		if (this.forwardBuffer.length < requiredSize) {
			const newSize = requiredSize * 2;
			this.forwardBuffer = new Int32Array(newSize);
			this.backwardBuffer = new Int32Array(newSize);
		}

		const forwardV = this.forwardBuffer.subarray(0, requiredSize);
		const backwardV = this.backwardBuffer.subarray(0, requiredSize);

		forwardV.fill(0);
		backwardV.fill(0);

		const delta = N - M;
		const isEven = (delta & 1) === 0;

		if (__DEV__ && debug) {
			console.log(`[_findMiddleSnake] N=${N}, M=${M}, delta=${delta}, isEven=${isEven}`);
		}

		const offsetPlus1 = offset + 1;
		forwardV[offsetPlus1] = 0;
		backwardV[offsetPlus1] = 0;

		const maxD = N + M;
		const shouldLogProgress = maxD > 10000;
		const hasProcessStdout = typeof process !== 'undefined' && process.stdout;

		for (let d = 0; d <= maxD; d++) {
			if (__DEV__ && debug) console.log(`\n=== d = ${d} ===`);
			if (shouldLogProgress && d > 0 && (d % 50) === 0 && hasProcessStdout) {
				process.stdout.write(`\r  - Middle snake search progress: ${d} / max ${maxD}`);
			}

			// Forward pass
			for (let k = -d; k <= d; k += 2) {
				const offsetK = offset + k;
				const offsetKMinus1 = offsetK - 1;
				const offsetKPlus1 = offsetK + 1;

				let x: number;
				if (k === -d || (k !== d && forwardV[offsetKMinus1] < forwardV[offsetKPlus1])) {
					x = forwardV[offsetKPlus1];
				} else {
					x = forwardV[offsetKMinus1] + 1;
				}
				let y = x - k;

				const startX = x;
				const startY = y;

				while (x < N && y < M && oldTokens[oldStart + x] === newTokens[newStart + y]) {
					x++;
					y++;
				}
				forwardV[offsetK] = x < N ? x : N;

				if (__DEV__ && debug) {
					console.log(`  FWD k=${k}: start=(${startX},${startY}) -> end=(${x},${y})`);
				}

				if (!isEven) {
					const kBack = k - delta;
					if (kBack >= -(d - 1) && kBack <= d - 1) {
						const x2 = N - backwardV[offset + kBack];
						if (x >= x2) {
							const y2 = x2 - k;
							if (x2 >= 0 && y2 >= 0 && y2 <= M && y >= 0) {
								if (__DEV__ && debug) {
									console.log(`  üü¢ ODD OVERLAP FOUND! k=${k}, kBack=${kBack}`);
									console.log(`     Forward end: (${x}, ${y})`);
									console.log(`     Backward start: (${x2}, ${y2})`);
									console.log(`     RETURNING snake: x=${x2}, y=${y2}, u=${x}, v=${y}`);
								}
								return { x: x2, y: y2, u: x, v: y };
							}
						}
					}
				}
			}

			// Backward pass
			for (let k = -d; k <= d; k += 2) {
				const offsetK = offset + k;
				const offsetKMinus1 = offsetK - 1;
				const offsetKPlus1 = offsetK + 1;

				let x2: number;
				if (k === -d || (k !== d && backwardV[offsetKMinus1] < backwardV[offsetKPlus1])) {
					x2 = backwardV[offsetKPlus1];
				} else {
					x2 = backwardV[offsetKMinus1] + 1;
				}
				let y2 = x2 - k;

				const startBackX = x2;
				const startBackY = y2;

				const oldEndMinus1 = oldEnd - 1;
				const newEndMinus1 = newEnd - 1;
				while (x2 < N && y2 < M && oldTokens[oldEndMinus1 - x2] === newTokens[newEndMinus1 - y2]) {
					x2++;
					y2++;
				}
				backwardV[offsetK] = x2 < N ? x2 : N;

				if (__DEV__ && debug) {
					console.log(`  BWD k=${k}: start=(${N - startBackX}, ${M - startBackY}) -> end=(${N - x2}, ${M - y2})`);
					console.log(`     (stored x2=${x2}, y2=${y2})`);
				}

				if (isEven) {
					const kForward = k + delta;
					if (kForward >= -d && kForward <= d) {
						const x1 = forwardV[offset + kForward];
						const u = N - x2;
						if (x1 >= u) {
							const y1 = x1 - kForward;
							const v = M - y2;
							if (u >= 0 && v >= 0 && y1 >= v) {
								if (__DEV__ && debug) {
									console.log(`  üü¢ EVEN OVERLAP FOUND! k=${k}, kForward=${kForward}`);
									console.log(`     Forward end: (${x1}, ${y1})`);
									console.log(`     Backward start: (${u}, ${v})`);
									console.log(`     RETURNING snake: x=${u}, y=${v}, u=${x1}, v=${y1}`);
								}
								return { x: u, y: v, u: x1, v: y1 };
							}
						}
					}
				}
			}
		}

		if (__DEV__ && debug) {
			console.log(`[_findMiddleSnake] No snake found. This should not happen.`);
		}
		return undefined;
	}

	/**
	 * [TOOLBOX] A fast, heuristic-based diff algorithm ("corridor diff").
	 * Does not guarantee SES, but stays close to the diagonal.
	 */
	public _guidedCalculateDiff(
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		idToString: string[],

		config: Required<DiffOptions>,
		debug: boolean
	): DiffResult[] {
		if (__DEV__ && debug) {
			console.log('[guidedCalculateDiff] START');
		}

		if (__DEV__ && debug) {
			console.log(`[_guidedCalculateDiff] Started. oldLen=${oldEnd - oldStart}, newLen=${newEnd - newStart}`);
		}

		const oldLen = oldEnd - oldStart;
		const newLen = newEnd - newStart;

		// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –î–ª—è –∞–±—Å—É—Ä–¥–Ω–æ –±–æ–ª—å—à–∏—Ö —Ä–∞–∑–ª–∏—á–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ + –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ
		const sizeRatio = oldLen > 0 && newLen > 0
			? Math.max(oldLen / newLen, newLen / oldLen)
			: 0;

		if (sizeRatio > 100 && (oldLen + newLen) > 500) {
			if (__DEV__ && debug) {
				console.log(`[_guidedCalculateDiff] Absurd size ratio (${sizeRatio.toFixed(1)}). Using simple add/remove.`);
			}
			const deletions = this._createDeletions(oldTokens, oldStart, oldEnd, idToString);
			const additions = this._createAdditions(newTokens, newStart, newEnd, idToString);
			deletions.push.apply(deletions, additions);
			return deletions;
		}

		const maxSize = oldLen + newLen;
		const operations = new Uint8Array(maxSize);
		const values = new Array<string>(maxSize);
		let resultLength = 0;

		const addOp = (op: DiffOperation, value: string): void => {
			operations[resultLength] = op;
			values[resultLength] = value;
			resultLength++;
		};

		let oldPos = oldStart;
		let newPos = newStart;

		const startDiagonal = newStart - oldStart;

		// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —à–∏—Ä–∏–Ω–∞ –∫–æ—Ä–∏–¥–æ—Ä–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞
		const adaptiveCorridorWidth = Math.min(
			config.corridorWidth,
			Math.max(10, Math.floor((oldLen + newLen) / 100))
		);

		// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π lookahead
		const adaptiveLookahead = Math.min(
			config.lookahead,
			Math.max(5, Math.floor((oldLen + newLen) / 200))
		);

		// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∏—Ç–µ—Ä–∞—Ü–∏–π —Å –∑–∞–ø–∞—Å–æ–º
		const maxIterations = oldLen + newLen + 100;
		let iterations = 0;

		// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: Early exit –ø–æ –ø—Ä–æ–≥—Ä–µ—Å—Å—É
		let lastProgressIteration = 0;
		let lastOldPos = oldPos;
		let lastNewPos = newPos;
		const stuckThreshold = Math.max(50, Math.floor(maxIterations / 10));

		if (__DEV__ && debug) {
			console.log(`[_guidedCalculateDiff] Adaptive params: corridor=${adaptiveCorridorWidth}, lookahead=${adaptiveLookahead}`);
		}

		while (oldPos < oldEnd || newPos < newEnd) {
			iterations++;

			// –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ
			if (iterations - lastProgressIteration > stuckThreshold) {
				if (__DEV__ && debug) {
					console.warn(`[_guidedCalculateDiff] Stuck detected after ${iterations} iterations. Flushing remaining.`);
				}
				while (oldPos < oldEnd) {
					addOp(DiffOperation.REMOVE, idToString[oldTokens[oldPos++]]);
				}
				while (newPos < newEnd) {
					addOp(DiffOperation.ADD, idToString[newTokens[newPos++]]);
				}
				break;
			}

			// –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
			if (oldPos > lastOldPos || newPos > lastNewPos) {
				lastProgressIteration = iterations;
				lastOldPos = oldPos;
				lastNewPos = newPos;
			}

			if (iterations > maxIterations) {
				if (__DEV__ && debug) {
					console.error(`[_guidedCalculateDiff] Max iterations ${maxIterations} exceeded!`);
				}
				while (oldPos < oldEnd) {
					addOp(DiffOperation.REMOVE, idToString[oldTokens[oldPos++]]);
				}
				while (newPos < newEnd) {
					addOp(DiffOperation.ADD, idToString[newTokens[newPos++]]);
				}
				break;
			}

			const canRemove = oldPos < oldEnd;
			const canAdd = newPos < newEnd;

			// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ë—ã—Å—Ç—Ä—ã–π –ø—É—Ç—å –¥–ª—è —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
			if (canRemove && canAdd && oldTokens[oldPos] === newTokens[newPos]) {
				addOp(DiffOperation.EQUAL, idToString[oldTokens[oldPos]]);
				oldPos++;
				newPos++;
				continue;
			}

			if (!canRemove) {
				addOp(DiffOperation.ADD, idToString[newTokens[newPos]]);
				newPos++;
				continue;
			}
			if (!canAdd) {
				addOp(DiffOperation.REMOVE, idToString[oldTokens[oldPos]]);
				oldPos++;
				continue;
			}

			// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä–∏–¥–æ—Ä–∞ —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —à–∏—Ä–∏–Ω–æ–π
			const currentDiagonal = newPos - oldPos;
			const diagonalDistance = Math.abs(currentDiagonal - startDiagonal);

			if (diagonalDistance > adaptiveCorridorWidth) {
				if (currentDiagonal > startDiagonal) {
					addOp(DiffOperation.REMOVE, idToString[oldTokens[oldPos]]);
					oldPos++;
				} else {
					addOp(DiffOperation.ADD, idToString[newTokens[newPos]]);
					newPos++;
				}
				continue;
			}

			const tokenToRemove = oldTokens[oldPos];
			const tokenToAdd = newTokens[newPos];

			// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: Lookahead —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
			let removeTokenFoundInNew = -1;
			const lookaheadNewLimit = Math.min(newEnd, newPos + adaptiveLookahead);
			for (let i = newPos + 1; i < lookaheadNewLimit; i++) {
				if (newTokens[i] === tokenToRemove) {
					removeTokenFoundInNew = i;
					break;
				}
			}

			let addTokenFoundInOld = -1;
			const lookaheadOldLimit = Math.min(oldEnd, oldPos + adaptiveLookahead);
			for (let i = oldPos + 1; i < lookaheadOldLimit; i++) {
				if (oldTokens[i] === tokenToAdd) {
					addTokenFoundInOld = i;
					break;
				}
			}

			// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –£–ª—É—á—à–µ–Ω–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –≤—ã–±–æ—Ä–∞
			if (removeTokenFoundInNew !== -1 && addTokenFoundInOld === -1) {
				addOp(DiffOperation.ADD, idToString[newTokens[newPos]]);
				newPos++;
				continue;
			}

			if (addTokenFoundInOld !== -1 && removeTokenFoundInNew === -1) {
				addOp(DiffOperation.REMOVE, idToString[oldTokens[oldPos]]);
				oldPos++;
				continue;
			}

			if (removeTokenFoundInNew !== -1 && addTokenFoundInOld !== -1) {
				const distanceToRemove = removeTokenFoundInNew - newPos;
				const distanceToAdd = addTokenFoundInOld - oldPos;

				// –í—ã–±–∏—Ä–∞–µ–º –±–æ–ª–µ–µ –±–ª–∏–∑–∫–∏–π
				if (distanceToRemove < distanceToAdd) {
					addOp(DiffOperation.ADD, idToString[newTokens[newPos]]);
					newPos++;
				} else {
					addOp(DiffOperation.REMOVE, idToString[oldTokens[oldPos]]);
					oldPos++;
				}
				continue;
			}

			// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–¥–∫–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞ (–±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è)
			const isRemoveTokenRare = this._isTokenRare(tokenToRemove, oldTokens, oldPos, oldEnd, 3);
			const isAddTokenRare = this._isTokenRare(tokenToAdd, newTokens, newPos, newEnd, 3);

			if (isRemoveTokenRare && !isAddTokenRare) {
				addOp(DiffOperation.ADD, idToString[newTokens[newPos]]);
				newPos++;
				continue;
			}

			if (isAddTokenRare && !isRemoveTokenRare) {
				addOp(DiffOperation.REMOVE, idToString[oldTokens[oldPos]]);
				oldPos++;
				continue;
			}

			// üéØ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –§–∏–Ω–∞–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ - –∏–¥–µ–º –ø–æ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω–æ–π —Å—Ç–æ—Ä–æ–Ω–µ
			if ((oldEnd - oldPos) > (newEnd - newPos)) {
				addOp(DiffOperation.REMOVE, idToString[oldTokens[oldPos]]);
				oldPos++;
			} else {
				addOp(DiffOperation.ADD, idToString[newTokens[newPos]]);
				newPos++;
			}
		}

		const result: DiffResult[] = new Array(resultLength);
		for (let i = 0; i < resultLength; i++) {
			result[i] = [operations[i], values[i]];
		}

		if (__DEV__ && debug) {
			console.log(`[_guidedCalculateDiff] Completed in ${iterations} iterations. Result length: ${resultLength}`);
		}

		return result;
	}

	/**
	 * [TOOLBOX] The basic (O(ND)) Myers diff algorithm.
	 * Finds the SES.
	 */
	public calculateDiff(
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		idToString: string[],
		config?: Required<DiffOptions>,
		debug?: boolean
	): DiffResult[] {
		const oldLen = oldEnd - oldStart;
		const newLen = newEnd - newStart;

		if (oldLen === 0) return this._createAdditions(newTokens, newStart, newEnd, idToString);
		if (newLen === 0) return this._createDeletions(oldTokens, oldStart, oldEnd, idToString);

		const max = oldLen + newLen;
		const offset = max;
		const v = new Int32Array(2 * max + 2);
		const trace: Int32Array[] = [];

		v[offset + 1] = 0;

		for (let d = 0; d <= max; d++) {
			trace.push(v.slice());
			for (let k = -d; k <= d; k += 2) {
				const kOffset = k + offset;
				let x: number;
				if (k === -d || (k !== d && v[kOffset - 1] < v[kOffset + 1])) {
					x = v[kOffset + 1]; // move down (insert)
				} else {
					x = v[kOffset - 1] + 1; // move right (delete)
				}
				let y = x - k;

				// –ï—Å–ª–∏ –º—ã –Ω–µ –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è ‚Äî –ø—Ä–æ–≤–µ—Ä–∏–º, –º–æ–∂–Ω–æ –ª–∏ –∏–∑–±–µ–∂–∞—Ç—å —Å–º–µ—â–µ–Ω–∏—è
				if (x < oldLen && y < newLen && oldTokens[oldStart + x] !== newTokens[newStart + y]) {
					// –ü—Ä–æ–≤–µ—Ä—è–µ–º: –∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ –°–õ–ï–î–£–Æ–©–ò–ô —Ç–æ–∫–µ–Ω? (—á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å EQUAL)
					const nextOld = x + 1 < oldLen ? oldTokens[oldStart + x + 1] : undefined;
					const nextNew = y + 1 < newLen ? newTokens[newStart + y + 1] : undefined;

					// –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç ‚Äî –∑–Ω–∞—á–∏—Ç, —Ç–µ–∫—É—â–∞—è –Ω–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å ‚Äî —ç—Ç–æ –∑–∞–º–µ–Ω–∞
					// –∏ –º—ã –º–æ–∂–µ–º —Å–º–µ–ª–æ —Å–¥–µ–ª–∞—Ç—å delete+insert –∑–¥–µ—Å—å, –Ω–µ —Å–º–µ—â–∞—è –±—É–¥—É—â–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
					if (nextOld !== undefined && nextNew !== undefined && nextOld === nextNew) {
						// –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ–∫—É—â—É—é –ø–∞—Ä—É ‚Äî –æ–Ω–∞ –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∫–∞–∫ delete+insert
						// –ù–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º: –∞–ª–≥–æ—Ä–∏—Ç–º –∏ —Ç–∞–∫ –ø–æ–π–¥—ë—Ç –ø–æ delete –∏–ª–∏ insert, –∞ EQUAL –ø—Ä–∏–¥—ë—Ç –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º —à–∞–≥–µ
					}
					// –ò–Ω–∞—á–µ ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ (–∞–ª–≥–æ—Ä–∏—Ç–º —Å–∞–º —Ä–∞–∑–±–µ—Ä—ë—Ç—Å—è)
				}
				// –ü—Ä–æ–¥–≤–∏–≥–∞–µ–º—Å—è –ø–æ –¥–∏–∞–≥–æ–Ω–∞–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
				while (x < oldLen && y < newLen && oldTokens[oldStart + x] === newTokens[newStart + y]) {
					x++;
					y++;
				}
				v[kOffset] = x;
				if (x >= oldLen && y >= newLen) {
					return this.buildValues(trace, oldTokens, oldStart, oldEnd, newTokens, newStart, newEnd, idToString);
				}
			}
		}
		return [];
	}

	/**
	 * [TOOLBOX] (Legacy) A stable diff algorithm that prioritizes
	 * finding positional anchors.
	 */

    public _calculateStableDiff(
    		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		idToString: string[],
		config: Required<DiffOptions>,
		debug: boolean
	): DiffResult[] {
		if (__DEV__ && debug) {
			console.log(`[_calculateStableDiff] START with preservePositions`);
		}

		const result: DiffResult[] = [];
		let oldPos = oldStart;
		let newPos = newStart;

		while (oldPos < oldEnd && newPos < newEnd) {
			if (oldTokens[oldPos] === newTokens[newPos]) {
				// –õ–æ–∫–∞–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - –¥–æ–±–∞–≤–ª—è–µ–º EQUAL
				result.push([DiffOperation.EQUAL, idToString[oldTokens[oldPos]]]);
				oldPos++;
				newPos++;
			} else {
				// –ù–∞—à–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ - –∏—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π –ª–æ–∫–∞–ª—å–Ω—ã–π —è–∫–æ—Ä—å
				const nextAnchor = this._findNextLocalAnchor(
					oldTokens, oldPos, oldEnd,
					newTokens, newPos, newEnd,
					config.localLookahead || 50, // –ù–∞—Å–∫–æ–ª—å–∫–æ –¥–∞–ª–µ–∫–æ –∏—Å–∫–∞—Ç—å
					debug
				);

				const gapOldEnd = nextAnchor?.oldPos ?? oldEnd;
				const gapNewEnd = nextAnchor?.newPos ?? newEnd;

				if (__DEV__ && debug) {
					console.log(`[_calculateStableDiff] Found gap: old[${oldPos}, ${gapOldEnd}) new[${newPos}, ${gapNewEnd})`);
					if (nextAnchor) {
						console.log(`  Next anchor at: old=${nextAnchor.oldPos}, new=${nextAnchor.newPos}`);
					}
				}

				// –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º gap –º–µ–∂–¥—É —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–µ–π –∏ —Å–ª–µ–¥—É—é—â–∏–º —è–∫–æ—Ä–µ–º
				const gapResult = this._processLocalGap(
					oldTokens, oldPos, gapOldEnd,
					newTokens, newPos, gapNewEnd,
					idToString, config, debug
				);
				result.push(...gapResult);

				// –ü–µ—Ä–µ–º–µ—â–∞–µ–º—Å—è –∫ —è–∫–æ—Ä—é
				if (nextAnchor) {
					oldPos = nextAnchor.oldPos;
					newPos = nextAnchor.newPos;
				} else {
					// –î–æ—à–ª–∏ –¥–æ –∫–æ–Ω—Ü–∞
					oldPos = oldEnd;
					newPos = newEnd;
				}
			}
		}

		// –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ö–≤–æ—Å—Ç—ã
		while (oldPos < oldEnd) {
			result.push([DiffOperation.REMOVE, idToString[oldTokens[oldPos++]]]);
		}
		while (newPos < newEnd) {
			result.push([DiffOperation.ADD, idToString[newTokens[newPos++]]]);
		}

		if (__DEV__ && debug) {
			console.log(`[_calculateStableDiff] END. Result length: ${result.length}`);
		}

		return result;
	}
	/**
	 * [TOOLBOX] Finds the next nearby positional anchor (L2 anchor).
	 */
	public _findNextLocalAnchor(
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		lookahead: number,
		debug: boolean
	): { oldPos: number; newPos: number } | null {
		const maxOldPos = Math.min(oldEnd, oldStart + lookahead);
		const maxNewPos = Math.min(newEnd, newStart + lookahead);

		// –ò—â–µ–º –±–ª–∏–∂–∞–π—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö lookahead
		for (let offset = 1; offset <= lookahead; offset++) {
			const oldPos = oldStart + offset;
			const newPos = newStart + offset;

			if (oldPos >= oldEnd || newPos >= newEnd) {
				break;
			}

			if (oldTokens[oldPos] === newTokens[newPos]) {
				if (__DEV__ && debug) {
					console.log(`[_findNextLocalAnchor] Found anchor at offset ${offset}: old=${oldPos}, new=${newPos}`);
				}
				return { oldPos, newPos };
			}
		}

		// –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∏–∞–≥–æ–Ω–∞–ª–∏
		for (let radius = 1; radius <= Math.min(lookahead / 2, 10); radius++) {
			for (let delta = -radius; delta <= radius; delta++) {
				const oldPos = oldStart + radius;
				const newPos = newStart + radius + delta;

				if (oldPos < oldEnd && newPos >= newStart && newPos < newEnd) {
					if (oldTokens[oldPos] === newTokens[newPos]) {
						if (__DEV__ && debug) {
							console.log(`[_findNextLocalAnchor] Found diagonal anchor: old=${oldPos}, new=${newPos} (delta=${delta})`);
						}
						return { oldPos, newPos };
					}
				}
			}
		}

		if (__DEV__ && debug) {
			console.log(`[_findNextLocalAnchor] No anchor found within lookahead ${lookahead}`);
		}
		return null;
	}

	/**
	 * [TOOLBOX] (Legacy) Processes a gap for `_calculateStableDiff`.
	 */
	public _processLocalGap(
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		idToString: string[],
		config: Required<DiffOptions>,
		debug: boolean
	): DiffResult[] {
		const gapOldLen = oldEnd - oldStart;
		const gapNewLen = newEnd - newStart;
		const result: DiffResult[] = [];

		if (__DEV__ && debug) {
			console.log(`[_processLocalGap] Processing gap: old[${oldStart}, ${oldEnd}) new[${newStart}, ${newEnd})`);
		}

		// –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö gaps –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é
		if (gapOldLen + gapNewLen < (config.localgap || 10)) {
			// –ü—Ä–æ—Å—Ç–æ —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –±–ª–æ–∫ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π
			for (let i = oldStart; i < oldEnd; i++) {
				result.push([DiffOperation.REMOVE, idToString[oldTokens[i]]]);
			}
			for (let i = newStart; i < newEnd; i++) {
				result.push([DiffOperation.ADD, idToString[newTokens[i]]]);
			}
		} else {
			// –î–ª—è –±–æ–ª—å—à–∏—Ö gaps –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—ã–π diff
			const gapResult = this.calculateDiff(
				oldTokens, oldStart, oldEnd,
				newTokens, newStart, newEnd,
				idToString, config, debug
			);
			result.push(...gapResult);
		}

		return result;
	}

	// =================================================================
	// [v6.0] –í–ù–£–¢–†–ï–ù–ù–ò–ï (PRIVATE) –•–ï–õ–ü–ï–†–´ –î–í–ò–ñ–ö–ê
	// (–ù–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é "Toolbox" –¥–ª—è –ø–ª–∞–≥–∏–Ω–æ–≤)
	// =================================================================

	/**
	 * Efficiently finds and separates common prefixes and suffixes from two token arrays.
	 * This preprocessing step reduces the problem size for the main diff algorithm.
	 * @private
	 */
	private _trimCommonPrefixSuffix(
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		idToString: string[],
		debug?: boolean,
	): {
		prefix: DiffResult[],
		suffix: DiffResult[],
		newOldStart: number,
		newOldEnd: number,
		newNewStart: number,
		newNewEnd: number
	} {
		if (__DEV__ && debug) {
			console.log('_trimCommonPrefixSuffix called:', {
				oldTokens: `${oldStart}-${oldEnd}`,
				newTokens: `${newStart}-${newEnd}`,
				oldLength: oldEnd - oldStart,
				newLength: newEnd - newStart
			});
		}

		const oldLen = oldEnd - oldStart;
		const newLen = newEnd - newStart;

		let prefixLen = 0;
		const minLen = Math.min(oldLen, newLen);
		while (prefixLen < minLen && oldTokens[oldStart + prefixLen] === newTokens[newStart + prefixLen]) {
			prefixLen++;
		}

		let suffixLen = 0;
		const remainingLen = minLen - prefixLen;
		while (suffixLen < remainingLen && oldTokens[oldEnd - 1 - suffixLen] === newTokens[newEnd - 1 - suffixLen]) {
			suffixLen++;
		}

		const prefix: DiffResult[] = new Array(prefixLen);
		for (let i = 0; i < prefixLen; i++) {
			prefix[i] = [DiffOperation.EQUAL, idToString[oldTokens[oldStart + i]]];
		}

		const suffix: DiffResult[] = new Array(suffixLen);
		for (let i = 0; i < suffixLen; i++) {
			suffix[i] = [DiffOperation.EQUAL, idToString[oldTokens[oldEnd - suffixLen + i]]];
		}

		const result = {
			prefix,
			suffix,
			newOldStart: oldStart + prefixLen,
			newOldEnd: oldEnd - suffixLen,
			newNewStart: newStart + prefixLen,
			newNewEnd: newEnd - suffixLen,
		};

		if (__DEV__ && debug) {
			console.log('_trimCommonPrefixSuffix result:', {
				prefixLength: prefixLen,
				suffixLength: suffixLen,
				trimmedOldRange: `${result.newOldStart}-${result.newOldEnd}`,
				trimmedNewRange: `${result.newNewStart}-${result.newNewEnd}`,
				prefix: prefix.map(p => p[1]),
				suffix: suffix.map(s => s[1])
			});
		}

		return result;
	}

	/**
	 * Converts arrays of string tokens into numerical IDs to speed up comparisons.
	 * This is a critical performance optimization, as integer comparisons are much
	 * faster than string comparisons.
	 * @private
	 */
	private _tokenize(
		oldTokens: string[],
		newTokens: string[],
		debug?: boolean
	): {
		hashedOld: Uint32Array
		hashedNew: Uint32Array
		idToString: string[]
	} {

		if (__DEV__ && debug) {
			console.log(`[_tokenize] Old tokens:`, oldTokens);
			console.log(`[_tokenize] New tokens:`, newTokens);
		}

		const totalTokens = oldTokens.length + newTokens.length;
		const tokenMap = new Map<string, number>();
		const idToString: string[] = [];
		let nextId = 0;

		const hashedOld = new Uint32Array(oldTokens.length);
		const hashedNew = new Uint32Array(newTokens.length);

		for (let i = 0; i < oldTokens.length; i++) {
			const token = oldTokens[i];
			let id = tokenMap.get(token);
			if (id === undefined) {
				id = nextId++;
				tokenMap.set(token, id);
				idToString.push(token);
			}
			hashedOld[i] = id;
		}

		for (let i = 0; i < newTokens.length; i++) {
			const token = newTokens[i];
			let id = tokenMap.get(token);
			if (id === undefined) {
				id = nextId++;
				tokenMap.set(token, id);
				idToString.push(token);
			}
			hashedNew[i] = id;
		}

		if (__DEV__ && debug) {
			console.log(`[_tokenize] Token map:`, Array.from(tokenMap.entries()));
			console.log(`[_tokenize] Hashed ${totalTokens} tokens into ${idToString.length} unique IDs.`);
		}
		return { hashedOld, hashedNew, idToString };
	}

	/**
	 * Helper method to determine if a token is rare within a given range.
	 * This is used as a heuristic in the guided diff algorithm.
	 * @private
	 */
	private _isTokenRare(
		token: number,
		tokens: Uint32Array,
		startPos: number,
		endPos: number,
		maxOccurrences: number,
		debug?: boolean
	): boolean {
		if (__DEV__ && debug) {
			console.log('_isTokenRare called:', {
				token,
				tokenRange: `${startPos}-${endPos}`,
				rangeLength: endPos - startPos,
				maxOccurrences
			});
		}

		let count = 0;
		for (let i = startPos; i < endPos; i++) {
			if (tokens[i] === token) {
				count++;
				if (count > maxOccurrences) {
					if (__DEV__ && debug) {
						console.log('_isTokenRare result: false (exceeded max occurrences)');
					}
					return false;
				}
			}
		}

		const result = count <= maxOccurrences;

		if (__DEV__ && debug) {
			console.log('_isTokenRare result:', {
				isRare: result,
				actualCount: count
			});
		}

		return result;
	}

	/**
	 * [TOOLBOX] Helper function to create an array of ADD operations.
	 */
	public _createAdditions(
		tokens: Uint32Array,
		start: number,
		end: number,
		idToString: string[],
		debug?: boolean
	): DiffResult[] {
		if (__DEV__ && debug) {
			console.log('_createAdditions called:', {
				range: `${start}-${end}`,
				length: end - start,
				tokens: Array.from(tokens.slice(start, end)).map(t => idToString[t])
			});
		}

		const res = new Array<DiffResult>(end - start);
		for (let i = 0; i < res.length; i++) {
			res[i] = [DiffOperation.ADD, idToString[tokens[start + i]]];
		}

		if (__DEV__ && debug) {
			console.log('_createAdditions result:', res);
		}

		return res;
	}

	/**
	 * [TOOLBOX] Helper function to create an array of REMOVE operations.
	 */
	public _createDeletions(
		tokens: Uint32Array,
		start: number,
		end: number,
		idToString: string[],
		debug?: boolean
	): DiffResult[] {
		if (__DEV__ && debug) {
			console.log('_createDeletions called:', {
				range: `${start}-${end}`,
				length: end - start,
				tokens: Array.from(tokens.slice(start, end)).map(t => idToString[t])
			});
		}

		const res = new Array<DiffResult>(end - start);
		for (let i = 0; i < res.length; i++) {
			res[i] = [DiffOperation.REMOVE, idToString[tokens[start + i]]];
		}

		if (__DEV__ && debug) {
			console.log('_createDeletions result:', res);
		}

		return res;
	}

	/**
	 * [TOOLBOX] Reconstructs the diff from the trace generated by `calculateDiff`.
	 */
	public buildValues(
		trace: Int32Array[],
		oldTokens: Uint32Array, oldStart: number, oldEnd: number,
		newTokens: Uint32Array, newStart: number, newEnd: number,
		idToString: string[]
	): DiffResult[] {
		// console.log('\n--- [buildValues START] ---');
		let x = oldEnd - oldStart;
		let y = newEnd - newStart;
		const result: DiffResult[] = [];
		const offset = oldEnd - oldStart + newEnd - newStart;
		// console.log(`Initial position: x=${x}, y=${y}. Trace history length: ${trace.length}`);

		for (let d = trace.length - 1; d >= 0; d--) {
			const v = trace[d];
			const k = x - y;
			const kOffset = k + offset;
			// console.log(`\n[d=${d}] Backtracking... Current position: (x=${x}, y=${y}), k=${k}`);

			const prevK = (k === -d || (k !== d && v[kOffset - 1] < v[kOffset + 1]))
				? k + 1
				: k - 1;
			const prevKOffset = prevK + offset;
			const prevX = v[prevKOffset];
			const prevY = prevX - prevK;
			// console.log(`  Calculated previous k=${prevK}. Previous position from trace: (prev_x=${prevX}, prev_y=${prevY})`);

			let snakeX = x;
			let snakeY = y;
			while (snakeX > prevX && snakeY > prevY) {
				const tokenValue = idToString[oldTokens[oldStart + snakeX - 1]];
				result.unshift([DiffOperation.EQUAL, tokenValue]);
				// console.log(`  SNAKE: Found EQUAL token "${tokenValue}" at (old:${snakeX - 1}, new:${snakeY - 1}). Prepending to result.`);
				snakeX--;
				snakeY--;
			}
			if (x !== snakeX || y !== snakeY) {
				// console.log(`  SNAKE END: Moved back from (x=${x}, y=${y}) to (x=${snakeX}, y=${snakeY})`);
			}

			if (d > 0) {
				if (prevX === snakeX) { // Down move, means addition
					const tokenValue = idToString[newTokens[newStart + snakeY - 1]];
					result.unshift([DiffOperation.ADD, tokenValue]);
					// console.log(`  OPERATION: ADD. Token: "${tokenValue}" from new[${newStart + snakeY - 1}]. Prepending to result.`);
				} else { // Right move, means removal
					const tokenValue = idToString[oldTokens[oldStart + snakeX - 1]];
					result.unshift([DiffOperation.REMOVE, tokenValue]);
					// console.log(`  OPERATION: REMOVE. Token: "${tokenValue}" from old[${oldStart + snakeX - 1}]. Prepending to result.`);
				}
			}

			x = prevX;
			y = prevY;

			if (x <= 0 && y <= 0) {
				// console.log(`[d=${d}] Reached origin (0,0). Backtracking complete.`);
				break;
			}
		}
		// console.log('--- [buildValues END] ---\n');
		return result;
	}

}